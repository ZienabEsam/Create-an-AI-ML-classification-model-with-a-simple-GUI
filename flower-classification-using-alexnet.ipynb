{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "91567713-b9d1-4d28-921e-85070085e3a1",
    "_uuid": "f0c11536-cd66-4243-8411-6878748d5948",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#importing liberaries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import pathlib\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "ffaecb4e-f26a-4cbd-9e53-d3de463eca2e",
    "_uuid": "8d7d6753-9d12-4beb-b4e3-18834b96d851",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "INIT_LR = 1e-1\n",
    "Batch_size =32\n",
    "Image_size = (128,128)\n",
    "directory_root = '/home/zesam/Downloads/My implentation/Flower classification using ALexNet/flowers'\n",
    "default_image_size = tuple((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "0d561178-be5b-4464-82e8-380014e39a0e",
    "_uuid": "7bc4ec8d-8ed3-4e09-a0d1-e995a8117adb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'sunflower', 'rose', 'dandelion', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(directory_root)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "2dff5507-b7d2-4abb-b2b6-c180eb70eacd",
    "_uuid": "8f0e7734-e3e7-4d1b-928b-b2ebdd4b2411",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#creating image list containing all Dataset images as directories\n",
    "image_dir_list = []\n",
    "label_list = []\n",
    "root_dir = listdir(directory_root)\n",
    "for plant_disease_folder in root_dir:\n",
    "    plant_disease_dir = listdir(f\"{directory_root}/{plant_disease_folder}\")\n",
    "    for image in plant_disease_dir:\n",
    "        plant_image_dir = f\"{directory_root}/{plant_disease_folder}/{image}\"\n",
    "        if plant_image_dir.endswith(\".jpg\") == True or plant_image_dir.endswith(\".JPG\") == True:\n",
    "            image_dir_list.append(plant_image_dir)\n",
    "            label_list.append(plant_disease_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all images in a list\n",
    "images_list= []\n",
    "for image_dir in image_dir_list:\n",
    "    if image_dir.endswith(\".jpg\") == True or image_dir.endswith(\".JPG\") == True:\n",
    "        image = cv2.imread(image_dir)\n",
    "        image = cv2.resize(image, default_image_size)   \n",
    "        image_array = img_to_array(image)\n",
    "        images_list.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4317, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#Converting images to numpy array with normalization\n",
    "np_image_list = np.array(images_list, dtype=np.float16) / 225.0\n",
    "print(np_image_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarizing labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "n_classes = len(label_binarizer.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np_image_list\n",
    "y = image_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test lists\n",
    "accuracy_test = []\n",
    "#Train lists\n",
    "accuracy_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "90/90 [==============================] - 133s 1s/step - loss: 0.6286 - accuracy: 0.4861\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 113s 1s/step - loss: 0.5772 - accuracy: 0.5605\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 111s 1s/step - loss: 0.5402 - accuracy: 0.6352\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 106s 1s/step - loss: 0.5211 - accuracy: 0.6605\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4959 - accuracy: 0.6932\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4821 - accuracy: 0.7099\n",
      "Epoch 7/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4559 - accuracy: 0.7543\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :49.61779013203614\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 55.90687977762335\n",
      "========================================\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :49.61779013203614\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 55.90687977762335\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zesam/.local/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "90/90 [==============================] - 146s 1s/step - loss: 0.6179 - accuracy: 0.5160\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 109s 1s/step - loss: 0.5695 - accuracy: 0.5813\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 106s 1s/step - loss: 0.5439 - accuracy: 0.6258\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 112s 1s/step - loss: 0.5125 - accuracy: 0.6727\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 110s 1s/step - loss: 0.4918 - accuracy: 0.7113\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 109s 1s/step - loss: 0.4687 - accuracy: 0.7436\n",
      "Epoch 7/7\n",
      "90/90 [==============================] - 106s 1s/step - loss: 0.4495 - accuracy: 0.7669\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :48.92286309937457\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 55.03822098679638\n",
      "========================================\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :48.92286309937457\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 55.03822098679638\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zesam/.local/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "90/90 [==============================] - 106s 1s/step - loss: 0.6219 - accuracy: 0.5073\n",
      "Epoch 2/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.5731 - accuracy: 0.5837\n",
      "Epoch 3/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.5425 - accuracy: 0.6345\n",
      "Epoch 4/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.5174 - accuracy: 0.6689\n",
      "Epoch 5/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4948 - accuracy: 0.6904\n",
      "Epoch 6/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4751 - accuracy: 0.7300\n",
      "Epoch 7/7\n",
      "90/90 [==============================] - 105s 1s/step - loss: 0.4511 - accuracy: 0.7620\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :50.590687977762336\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 61.257817929117444\n",
      "========================================\n",
      "Test Evaluation\n",
      "========================================\n",
      "Test accuracy is :50.590687977762336\n",
      "========================================\n",
      "Train Evaluation\n",
      "========================================\n",
      "Training accuracy is : 61.257817929117444\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 3\n",
    "\n",
    "kf = KFold(n_splits= k, random_state=True, shuffle=True)\n",
    "for train_index, test_index in kf.split(X) :\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    np.random.seed(1000)\n",
    "\n",
    "    #Instantiation\n",
    "    AlexNet = Sequential()\n",
    "\n",
    "    #1st Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=96, input_shape=(128,128,3), kernel_size=(11,11), strides=(4,4), padding ='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #2nd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #3rd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "\n",
    "    #4th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "\n",
    "    #5th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #Passing it to a Fully Connected layer\n",
    "    AlexNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #2nd Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "   #3rd Fully Connected Layer\n",
    "    AlexNet.add(Dense(1000))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #Output Layer\n",
    "    AlexNet.add(Dense(5))\n",
    "    AlexNet.add(BatchNormalization())\n",
    "    AlexNet.add(Activation('softmax'))\n",
    "    AlexNet.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0003), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "   \n",
    "    #training model\n",
    "    \n",
    "    AlexNet.fit(X_train,y_train,epochs = 7)\n",
    "    #model prediction \n",
    "  \n",
    "    Model_pred_train = AlexNet.predict(X_train)\n",
    "  \n",
    "    Model_pred_test =  AlexNet.predict(X_test)\n",
    "\n",
    "    \n",
    "    Model_pred_test = Model_pred_test > 0.5\n",
    "    Model_pred_train = Model_pred_train > 0.5\n",
    "    \n",
    " \n",
    "    ################################################33\n",
    "    print(\"Test Evaluation\")\n",
    "    print(\"=\"*40)\n",
    "    #Calculating Test accuracy\n",
    "    print('Test accuracy is :' + str(accuracy_score(y_test,Model_pred_test)*100))\n",
    "    accuracy = accuracy_score(y_test,Model_pred_test)*100\n",
    "    accuracy_test.append(accuracy)\n",
    "    ################################################################\n",
    "    print(\"=\"*40)\n",
    "    print(\"Train Evaluation\")\n",
    "    print(\"=\"*40)\n",
    "    print('Training accuracy is : ' + str(accuracy_score(y_train,Model_pred_train)*100))\n",
    "    t_accuracy = accuracy_score(y_train,Model_pred_train)*100\n",
    "    accuracy_train.append(t_accuracy)  \n",
    "    #################################################################\n",
    "    print(\"=\"*40)\n",
    "    #model prediction \n",
    "  \n",
    "    Model_pred_train = AlexNet.predict(X_train)\n",
    "  \n",
    "    Model_pred_test =  AlexNet.predict(X_test)\n",
    "\n",
    "    \n",
    "    Model_pred_test = Model_pred_test > 0.5\n",
    "    Model_pred_train = Model_pred_train > 0.5\n",
    "    \n",
    " \n",
    "    ################################################33\n",
    "    print(\"Test Evaluation\")\n",
    "    print(\"=\"*40)\n",
    "    #Calculating Test accuracy\n",
    "    print('Test accuracy is :' + str(accuracy_score(y_test,Model_pred_test)*100))\n",
    "    accuracy = accuracy_score(y_test,Model_pred_test)*100\n",
    "    accuracy_test.append(accuracy)\n",
    "    ################################################################\n",
    "    print(\"=\"*40)\n",
    "    print(\"Train Evaluation\")\n",
    "    print(\"=\"*40)\n",
    "    print('Training accuracy is : ' + str(accuracy_score(y_train,Model_pred_train)*100))\n",
    "    t_accuracy = accuracy_score(y_train,Model_pred_train)*100\n",
    "    accuracy_train.append(t_accuracy)  \n",
    "    #################################################################\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "from PIL import Image, ImageTk\n",
    "BaymaxLittleScreen = tk.Tk()\n",
    "BaymaxLittleScreen.geometry(\"400x400\")  # Size of the window \n",
    "BaymaxLittleScreen.title('Dr.BayMax the intern')\n",
    "my_font1=('times', 18, 'bold')\n",
    "my_font2 = ('italic',10 , 'bold')\n",
    "\n",
    "#DR.BayMax Label\n",
    "l1 = tk.Label(BaymaxLittleScreen,text='Dr.BayMax',width=30,font=my_font1)  \n",
    "l1.grid(row=1,column=1)\n",
    "#Upload file Button\n",
    "b1 = tk.Button(BaymaxLittleScreen, text='Upload File', width=20,command = lambda:upload_file())\n",
    "b1.grid(row=2,column=1)\n",
    "#show predictions \n",
    "b3 = tk.Button(BaymaxLittleScreen, text='Show Classification', width=20,command = lambda:ShowClassification())\n",
    "b3.grid(row=8,column=1)\n",
    "l2 = tk.Label(BaymaxLittleScreen,text='Classification',width=30,font=my_font1)  \n",
    "l2.grid(row=10,column=1)\n",
    "\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    global img\n",
    "    f_types = [('Jpg Files', '*.jpg')]\n",
    "    global filename\n",
    "    filename = filedialog.askopenfilename(filetypes=f_types)\n",
    "    #Preview Image on the Pane \n",
    "    img = ImageTk.PhotoImage(file=filename)\n",
    "    b2 =tk.Button(BaymaxLittleScreen,image=img) # using Button \n",
    "    b2.grid(row=3,column=1)\n",
    "    global image_to_Save \n",
    "    #creating image object to create their directory\n",
    "    image_to_Save = Image.open(filename)\n",
    "    image_To_Save = open_file(image_to_Save) #Whatever the given image is    \n",
    "    \n",
    "    \n",
    "def open_file(self):\n",
    "    curr_directory = os.getcwd()\n",
    "    self.file_path = filename\n",
    "    save_path = \"/home/zesam/Downloads/My implentation/Skin Disease Detection using CNN\"\n",
    "    file_name = \"test.jpg\"\n",
    "    global complete_name\n",
    "    complete_name = os.path.join(save_path, file_name)\n",
    "    image_to_Save.save(complete_name)\n",
    "    if self.file_path is not None:\n",
    "        pass    \n",
    "\n",
    "\n",
    "def ShowClassification():\n",
    "    img_path = complete_name\n",
    "    image = tf.keras.preprocessing.image.load_img(img_path, target_size=(96, 96))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])\n",
    "    input_arr = input_arr.astype('float32') / 255.0\n",
    "    prediction = AlexNet.predict(input_arr)\n",
    "    if(prediction == 1 ):\n",
    "        l3 = tk.Label(BaymaxLittleScreen,text='Vtiligo Case',width=30,font= my_font2)\n",
    "        l3.grid(row=12,column=1) \n",
    "    else:\n",
    "        l4 = tk.Label(BaymaxLittleScreen,text='Healthy skin',width=30,font= my_font2)\n",
    "        l4.grid(row=14,column=1)\n",
    "        \n",
    "    plot.imshow(prediction, interpolation='nearest')\n",
    "    plot.show()\n",
    "BaymaxLittleScreen.mainloop()  # Keep the window open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_avg = 0\n",
    "for accuracy in accuracy_test:\n",
    "    test_accuracy_avg += accuracy\n",
    "test_accuracy_average = test_accuracy_avg/k\n",
    "print(\"Accuracy array: \" + str(accuracy_test))\n",
    "print(\"Average Accuracy : \" + str(test_accuracy_average))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_avg = 0\n",
    "for train_accuracy in accuracy_train:\n",
    "    train_accuracy_avg += train_accuracy\n",
    "train_accuracy_average = train_accuracy_avg/k\n",
    "print(accuracy_train)\n",
    "print(\"=\"*40)\n",
    "print(\"Train accuracy average: \"+ str(train_accuracy_average))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
